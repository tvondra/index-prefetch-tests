index prefetch tests
====================

* `csv` - raw benchmark results in CSV format
* `patches` - the evaluated patch series
* `pdf` - table of results in PDF format
* `png` - table of results in PNG format
* `preadv-tests` - fadvise/preadv2 microbenchmarks 
* `scripts` - scripts used to run the benchmarks


test scripts basics
-------------------

The test scripts execute queries on synthetic data sets with various
access patterns (sequential, random, ...), forcing a particular types
of scans (index, index-only, seqscan, bitmap), and measure the timing.
Different types of indexes are used (btree/hash), etc.

The scripts may test multiple builds in one run, but restarting the
instance with different build. The scripts also occasionally restart
the instance and/or drop cache to prevent caching at different levels
(shared buffers, kernel).

The script also determine if the forced query plan is the best one (i.e.
if it'd be used even without forcing it through `enable_` options).

Each script produces a CSV file with these columns:

* `test` - type of test, identifies the workload (e.g. `btree`, `hash`)

* `machine` - specified by user, identifies the machine, useful when
   running the script on multiple different machines

* `time` - unix timestamp of the query execution

* `rows` - size of the dataset (e.g. 1000000 rows)

* `dataset` - pattern, generated by the script (e.g. `random`, `cycle`
   or `sequential`)

* `matches` - number of rows per key value (e.g. 1000 means `WHERE a = 1`
   would return ~1000 rows

* `distinct` - number of distinct key values (i.e. `nrows/matches`)

* `build` - identifies the build tested

* `prefetch` - value for `effective_io_concurrency` (e.g. 0, 8 or 32)

* `table_size` - size of the generated table

* `index_size` size of the generated index

* `scan` - type of scan (`indexscan`, `indexonlyscan`, ...)

* `caching` - was the data cached? `cached` - neither instance/kernel
   caches were dropped, `cached-os` - instance was restarted to drop
   shared buffers, `uncached` - both intance/kernel caches were dropped

* `run` - number of this run (each query gets executed 5-times for each
   combination of parameters)

* `value` - key value used in the query

* `nfound` - number of matches (should be close to `matches`)

* `cost` - estimated cost of the query

* `duration` - timing of the query

* `best_plan` - is this the best plan (would it be chosen by optimizer?)

* `correct_plan` - is this a correct plan (did we force the right scan?)

